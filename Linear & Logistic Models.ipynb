{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyHRT94hErCRigPXAhZPBA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","\n","# Linear Regression Model\n","class LinearRegression:\n","    def __init__(self, learning_rate=0.01, iterations=1000):\n","        self.learning_rate = learning_rate\n","        self.iterations = iterations\n","\n","    def fit(self, X, y):\n","        self.m, self.n = X.shape\n","        # Initialize parameters to zero, considering the bias term\n","        self.theta = np.zeros(self.n + 1)\n","        self.X = np.c_[np.ones(self.m), X]  # Add bias term (intercept)\n","        self.y = y\n","\n","        # Gradient Descent\n","        for _ in range(self.iterations):\n","            self.theta -= self.learning_rate * self.gradient()\n","\n","    def gradient(self):\n","        predictions = self.X.dot(self.theta)\n","        errors = predictions - self.y\n","        return (1/self.m) * self.X.T.dot(errors)\n","\n","    def predict(self, X):\n","        X = np.c_[np.ones(X.shape[0]), X]\n","        return X.dot(self.theta)"],"metadata":{"id":"Glur4ZPLfOCx","executionInfo":{"status":"ok","timestamp":1729202288333,"user_tz":-330,"elapsed":451,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","X = np.array([[1], [2], [3], [4]])\n","y = np.array([2, 3, 4, 5])\n","model = LinearRegression()\n","model.fit(X, y)\n","print(model.predict(np.array([[5]])))  # Predict new value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5bC5YGade7ZS","executionInfo":{"status":"ok","timestamp":1729202293097,"user_tz":-330,"elapsed":436,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}},"outputId":"493f52c1-f7d5-4f3d-8cfa-f3e9d219a63d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[6.09263909]\n"]}]},{"cell_type":"code","source":["# Sigmoid function\n","def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","\n","# Logistic Regression Model\n","class LogisticRegression:\n","    def __init__(self, learning_rate=0.01, iterations=1000):\n","        self.learning_rate = learning_rate\n","        self.iterations = iterations\n","\n","    def fit(self, X, y):\n","        self.m, self.n = X.shape\n","        self.theta = np.zeros(self.n)\n","        self.X = np.c_[np.ones(self.m), X]\n","        self.y = y\n","\n","        for _ in range(self.iterations):\n","            self.theta -= self.learning_rate * self.gradient()\n","\n","    def gradient(self):\n","        predictions = sigmoid(self.X.dot(self.theta))\n","        errors = predictions - self.y\n","        return (1/self.m) * self.X.T.dot(errors)\n","\n","    def predict(self, X):\n","        X = np.c_[np.ones(X.shape[0]), X]\n","        return sigmoid(X.dot(self.theta)) >= 0.5  # Classify as 1 if probability >= 0.5\n","\n","# Example usage:\n","# X = np.array([[1], [2], [3], [4]])\n","# y = np.array([0, 0, 1, 1])\n","# model = LogisticRegression()\n","# model.fit(X, y)\n","# print(model.predict(np.array([[5]])))  # Predict new class\n","# Sigmoid function\n","def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","\n","# Logistic Regression Model\n","class LogisticRegression:\n","    def __init__(self, learning_rate=0.01, iterations=1000):\n","        self.learning_rate = learning_rate\n","        self.iterations = iterations\n","\n","    def fit(self, X, y):\n","        self.m, self.n = X.shape\n","        self.theta = np.zeros(self.n)\n","        self.X = np.c_[np.ones(self.m), X]\n","        self.y = y\n","\n","        for _ in range(self.iterations):\n","            self.theta -= self.learning_rate * self.gradient()\n","\n","    def gradient(self):\n","        predictions = sigmoid(self.X.dot(self.theta))\n","        errors = predictions - self.y\n","        return (1/self.m) * self.X.T.dot(errors)\n","\n","    def predict(self, X):\n","        X = np.c_[np.ones(X.shape[0]), X]\n","        return sigmoid(X.dot(self.theta)) >= 0.5  # Classify as 1 if probability >= 0.5\n","\n"],"metadata":{"id":"Gz2ZTfjQfj3B","executionInfo":{"status":"ok","timestamp":1729202389819,"user_tz":-330,"elapsed":448,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","X = np.array([[1], [2], [3], [4]])  # Removed the extra space at the beginning of this line\n","y = np.array([0, 0, 1, 1])\n","model = LogisticRegression()\n","model.fit(X, y)\n","print(model.predict(np.array([[5]])))  # Predict new class"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poCYYODbgGw-","executionInfo":{"status":"ok","timestamp":1729202724062,"user_tz":-330,"elapsed":442,"user":{"displayName":"KUMAR","userId":"05098059224781946972"}},"outputId":"a2827d6b-caae-4c89-b0be-71e4fdaa302c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[ True]\n"]}]}]}